{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1OpdJ2rDuIuisAzrS8yy21y0h5rDVIl5V","authorship_tag":"ABX9TyNaEc9SSK8RHjFZrSH3MFAt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# LDA"],"metadata":{"id":"a-99u0fKo99I"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OmPMy2ypRKnm","executionInfo":{"status":"ok","timestamp":1696295652277,"user_tz":-420,"elapsed":5103,"user":{"displayName":"Muhammad Fanky Andriansyah","userId":"16491308129804645261"}},"outputId":"675106e9-01e3-44dc-fed7-b7c286e84026"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"]}],"source":["pip install pandas"]},{"cell_type":"code","source":["import gensim\n","from gensim import corpora\n","from gensim.models import LdaModel\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","import pandas as pd"],"metadata":{"id":"26fdU9hERbEt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DataAbstrak.csv')"],"metadata":{"id":"z0RcEenSRjDD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k-DSb9krSQ3k","executionInfo":{"status":"ok","timestamp":1696291239444,"user_tz":-420,"elapsed":373,"user":{"displayName":"Muhammad Fanky Andriansyah","userId":"16491308129804645261"}},"outputId":"4be270cf-0db0-4007-b51f-b6401789c2a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["     Unnamed: 0                                            Abstrak\n","0             0  maka dan minuman khas merupakan ciri dari keka...\n","1             1  abstrak akhir akhir ini semakin maraknya pencu...\n","2             2  penelitian ini bertujuan untuk dapat mengetahu...\n","3             3  perairan soccah merupakan lokasi nelayan menca...\n","4             4  abstrak rian pandi pranata nim program studi s...\n","..          ...                                                ...\n","140         140  analisis bahasa figuratif yang digunakan dalam...\n","141         141  abstrak tujuan dari penelitian ini adalah untu...\n","142         142  penelitian ini dilatarbelakangi oleh kesulitan...\n","143         143  abstrak abstrak penelitian ini mengkaji bentuk...\n","144         144  abstrak produksi garam krosok di salt house me...\n","\n","[145 rows x 2 columns]\n"]}]},{"cell_type":"code","source":["# Mengambil Semua Nilai Dalam Kolom Abstrak Dari Data, Disimpan ke dalam bentuk list\n","documents = data['Abstrak'].tolist()"],"metadata":{"id":"oBWnl1WPSVCe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Instal Modul NLTK\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","stop_words = set(stopwords.words('english')) # Memberhentikan kata2 berhenti/kata2 umum\n","lemmatizer = WordNetLemmatizer() # Mengurangi Variasi Kata\n","tokenized_documents = [] # Membuat List Kosong\n","\n","# PraPemrosesan Untuk Menyederhanakan Kata\n","for doc in documents:\n","    words = word_tokenize(doc.lower())\n","    filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n","    lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_words]\n","    tokenized_documents.append(lemmatized_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vSxsvJsdSkfm","executionInfo":{"status":"ok","timestamp":1696295666470,"user_tz":-420,"elapsed":2037,"user":{"displayName":"Muhammad Fanky Andriansyah","userId":"16491308129804645261"}},"outputId":"7709e082-ab04-422b-d79a-2e6f16bc2e2e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"code","source":["dictionary = corpora.Dictionary(tokenized_documents)  # Membuat kamus/daftar kata2 dan diberi indeks numerik"],"metadata":{"id":"ICUMKZUVSmI4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["corpus = [dictionary.doc2bow(doc) for doc in tokenized_documents] # Mengubah Dokumen ke dalam representasi Vector BoW"],"metadata":{"id":"uhhqAB2gTMgB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lda_model = LdaModel(corpus, num_topics=3, id2word=dictionary, passes=15) # Melatih model LDA"],"metadata":{"id":"MpoW_xutTQFF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for idx, topic in lda_model.print_topics():\n","    print(f\"Topik #{idx + 1}: {topic}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KF9qRpJfTT2m","executionInfo":{"status":"ok","timestamp":1696295687453,"user_tz":-420,"elapsed":8,"user":{"displayName":"Muhammad Fanky Andriansyah","userId":"16491308129804645261"}},"outputId":"88ab5755-7778-4859-dd45-913ac6cc4aaf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Topik #1: 0.029*\"dan\" + 0.025*\"yang\" + 0.020*\"penelitian\" + 0.018*\"ini\" + 0.017*\"dengan\" + 0.013*\"dalam\" + 0.011*\"di\" + 0.011*\"dari\" + 0.011*\"pada\" + 0.010*\"untuk\"\n","Topik #2: 0.029*\"yang\" + 0.029*\"dan\" + 0.016*\"dengan\" + 0.015*\"penelitian\" + 0.012*\"ini\" + 0.011*\"dalam\" + 0.010*\"untuk\" + 0.008*\"pada\" + 0.008*\"data\" + 0.008*\"di\"\n","Topik #3: 0.022*\"yang\" + 0.017*\"dan\" + 0.013*\"penelitian\" + 0.013*\"dengan\" + 0.012*\"dalam\" + 0.010*\"ini\" + 0.008*\"risiko\" + 0.008*\"pada\" + 0.008*\"kerja\" + 0.007*\"undang\"\n"]}]},{"cell_type":"code","source":["# Membuat DataFrame untuk menampilkan proporsi topik dalam dokumen\n","document_topic_df = pd.DataFrame()\n","\n","for doc in corpus:\n","    topic_distribution = lda_model.get_document_topics(doc, minimum_probability=0)\n","    doc_topic_props = {f\"Topik {topic_id + 1}\": prop for topic_id, prop in topic_distribution}\n","    doc_topic_props = {} #mengubah tampilan agar topik di probalility hilang dan ada pada tabel diatasnya\n","    for topic_id, prob in topic_distribution:\n","        key = f\"Topik {topic_id + 1}\"\n","        doc_topic_props[key] = prob\n","    document_topic_df = pd.concat([document_topic_df, pd.Series(doc_topic_props)], ignore_index=True, axis=1)\n","\n","document_topic_df = document_topic_df.transpose()  # Transpose agar topik menjadi kolom\n","\n","# Menampilkan tabel proporsi topik dalam dokumen\n","print(\"Tabel Proporsi Topik dalam Dokumen:\")\n","print(document_topic_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z2iTBsya5CCC","executionInfo":{"status":"ok","timestamp":1696295690818,"user_tz":-420,"elapsed":964,"user":{"displayName":"Muhammad Fanky Andriansyah","userId":"16491308129804645261"}},"outputId":"9c38aa7e-8dc0-4698-d477-52d400012f99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tabel Proporsi Topik dalam Dokumen:\n","      Topik 1   Topik 2   Topik 3\n","0    0.996069  0.001993  0.001938\n","1    0.001440  0.001403  0.997157\n","2    0.459788  0.537571  0.002642\n","3    0.002254  0.995677  0.002069\n","4    0.995903  0.002020  0.002078\n","..        ...       ...       ...\n","140  0.002182  0.995825  0.001993\n","141  0.993431  0.003262  0.003307\n","142  0.001788  0.120710  0.877502\n","143  0.002368  0.002339  0.995293\n","144  0.995460  0.002299  0.002241\n","\n","[145 rows x 3 columns]\n"]}]},{"cell_type":"code","source":["# Membuat DataFrame untuk menampilkan proporsi kata dalam topik\n","topic_word_df = pd.DataFrame()\n","\n","for topic_id in range(lda_model.num_topics):\n","    topic_words = lda_model.show_topic(topic_id, topn=10)  # mengambil 10 kata kunci teratas\n","    words_list = [word for word, _ in topic_words]\n","    words_list = []\n","    for word, bbt in topic_words:\n","        words_list.append(word)\n","    topic_word_df[f\"Topik {topic_id + 1}\"] = words_list\n","\n","# Menampilkan tabel proporsi kata dalam topik\n","print(\"\\nTabel Proporsi Kata dalam Topik:\")\n","print(topic_word_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uUkE1T_75SOi","executionInfo":{"status":"ok","timestamp":1696295834767,"user_tz":-420,"elapsed":5,"user":{"displayName":"Muhammad Fanky Andriansyah","userId":"16491308129804645261"}},"outputId":"8ad64add-895c-4d27-d541-411addd61d62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Tabel Proporsi Kata dalam Topik:\n","      Topik 1     Topik 2     Topik 3\n","0         dan        yang        yang\n","1        yang         dan         dan\n","2  penelitian      dengan  penelitian\n","3         ini  penelitian      dengan\n","4      dengan         ini       dalam\n","5       dalam       dalam         ini\n","6          di       untuk      risiko\n","7        dari        pada        pada\n","8        pada        data       kerja\n","9       untuk          di      undang\n"]}]}]}